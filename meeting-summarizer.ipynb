{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup for upload to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "import moviepy.editor as mp \n",
    "import json\n",
    "import sys\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huuuyeah/meetingbank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "prefix = \"summarize: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "\n",
    "    inputs = [prefix + doc for doc in examples[\"transcript\"]]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"meeting_summarizer_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am secretary. Please close the voting and announce the results. It is eight is final consideration of Council Bill 1013 with its public hearing has been postponed until Monday, December 10th. Madam Secretary, if you please put the next item up on our screens and Councilwoman Black, will you please be accountable? 1006 on the floor for passage? Yes. I move that council bill 1006 be placed upon final consideration and do pass. It has been moved and seconded. Councilwoman Black, your motion to postpone. I move that final consideration of Council Bill 18, dash 1006 with its public hearing be postponed to Monday, November 19th, 2018. And it looks like that has been moved and seconded. Questions or comments from members of Council Councilman Black. This postponement was requested by the applicant and is not a reflection on the merits of the application. All right. See no other questions or comments. Madam Secretary, Raquel. Black Eye. Espinosa. Hi. Flynn. I. Cashman. Hi. Lopez. I knew Ortega. I. Mr. President. Madam Secretary, please close voting and announce results. Eight Eyes Final Consideration of Council Bill 1006 with its public hearing has been postponed until Monday, November 19th. All right. Wraps up everything that was called out, all other bills for introduction or published. And we are now ready for the block vote on resolutions and bills on final consideration. Council members remember that this is a consent or block vote and you will need to vote I. Otherwise, this is your last chance to call it an item for a separate vote. Councilman Black, would you please put the resolutions for adoption and the bills on final consideration for final passage on the floor? Yes, I move that resolutions be adopted and bills and final, final consideration be placed upon final consideration and do pass in a block for the following items. All Series 18 1180 1224 1230. 1097 1220 1221 1228 zero 936 1188 1332 1198 1199 1200 1201 1196. That's it. All right. Thank you, Councilman Black. It has been moved and seconded. Madam Secretary, roll call. Black eye. Espinosa. Hi. Flynn. Hi. Cashman. Hi. Lopez. All right. Ortega. Hi, Mr. President. I am secretary. Please close the voting. Announce the results. 88 ayes. The resolutions have been adopted and bills have been placed upon final consideration and do pass. Tonight there will be a required public hearing on Council Bill 996 changing the zoning classification of 374023850 York Street in the Clayton neighborhood.\"\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"cameronslee/meeting_summarizer_model\")\n",
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper_timestamped as whisper\n",
    "import json\n",
    "def get_transcript(input_file):\n",
    "    root, extention  = os.path.splitext(input_file)\n",
    "    audio = whisper.load_audio(input_file)\n",
    "    model = whisper.load_model(\"base\")\n",
    "\n",
    "    result = whisper.transcribe(model, audio, language=\"en\")\n",
    "\n",
    "    # Specify the file path where you want to save the JSON data\n",
    "    output_file = root+\".json\"\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(result, file, indent=2, ensure_ascii=False)\n",
    "\n",
    "    return result\n",
    "\n",
    "input_file = \"test1.mp4\"\n",
    "transcript = get_transcript(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file\n",
    "f = open ('test1.json', \"r\")\n",
    "data = json.loads(f.read())\n",
    "\n",
    "transcript = data['text']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(transcript):\n",
    "    summary =  summarizer(\"summarize: \"+transcript)\n",
    "    return summary\n",
    "get_summary(transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
